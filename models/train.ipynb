{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6345c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VIDUSHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016813d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "try:\n",
    "    dataset = json.loads(raw)\n",
    "except json.JSONDecodeError:\n",
    "    dataset = []\n",
    "    for line in raw.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            dataset.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            # Skip malformed lines; adjust if you need strict validation\n",
    "            continue\n",
    "\n",
    "# Handle if dataset is a dict with a list inside, or directly a list\n",
    "if isinstance(dataset, dict):\n",
    "    for key, value in dataset.items():\n",
    "        if isinstance(value, list):\n",
    "            dataset = value\n",
    "            break\n",
    "\n",
    "positives = []\n",
    "for x in dataset:\n",
    "    positives.append((x.get(\"question\"), x.get(\"exp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753deab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182822"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7141b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [x[\"exp\"] for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b35df9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy -ves \n",
    "def build_easy_negatives(dataset, gold_key_question=\"question\", gold_key_passage=\"exp\", max_attempts=10):\n",
    "    all_passages = [x.get(gold_key_passage) for x in dataset if x.get(gold_key_passage)]\n",
    "    easy_negatives = []\n",
    "    for item in dataset:\n",
    "        q = item.get(gold_key_question)\n",
    "        gold = item.get(gold_key_passage)\n",
    "        if not q or not gold or not all_passages:\n",
    "            continue\n",
    "        candidate = gold\n",
    "        tries = 0\n",
    "        while candidate == gold and tries < max_attempts:\n",
    "            candidate = random.choice(all_passages)\n",
    "            tries += 1\n",
    "        if candidate != gold:\n",
    "            easy_negatives.append((q, candidate))\n",
    "    return easy_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baedd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_negatives = build_easy_negatives(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3ebd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hard_negatives(dataset, gold_key_question=\"question\", gold_key_passage=\"exp\", sample_size=1000):\n",
    "    all_passages = [x.get(gold_key_passage) for x in dataset if x.get(gold_key_passage)]\n",
    "    \n",
    "    # Sample to speed up BM25 indexing\n",
    "    if len(all_passages) > sample_size:\n",
    "        sampled_idx = random.sample(range(len(all_passages)), sample_size)\n",
    "        all_passages = [all_passages[i] for i in sampled_idx]\n",
    "    \n",
    "    # Build BM25 index\n",
    "    corpus_tokens = [p.lower().split() for p in all_passages]\n",
    "    bm25 = BM25Okapi(corpus_tokens)\n",
    "    \n",
    "    hard_negatives = []\n",
    "    for item in dataset:\n",
    "        q = item.get(gold_key_question)\n",
    "        gold = item.get(gold_key_passage)\n",
    "        if not q or not gold:\n",
    "            continue\n",
    "        \n",
    "        # BM25 rank\n",
    "        q_tokens = q.lower().split()\n",
    "        scores = bm25.get_scores(q_tokens)\n",
    "        ranked = sorted(zip(all_passages, scores), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Take top non-gold passage\n",
    "        for passage, _ in ranked:\n",
    "            if passage != gold:\n",
    "                hard_negatives.append((q, passage))\n",
    "                break\n",
    "    \n",
    "    return hard_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f496fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_negatives = build_hard_negatives(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c399063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of generated pairs:\n",
      "positives: 182822 | easy_negatives: 160869 | hard_negatives: 160869\n",
      "sample easy negative: ('Chronic urethral obstruction due to benign prismatic hyperplasia can lead to the following change in kidney parenchyma', \"Ans. is 'b' i.e., Preformed toxin . Vomiting within 6 hours of ingestion of rice suggests the diagnosis of emetic type of food poisoning caused by B. cereus. . It caused by preformed heat stable enterotoxin. . In emetic form, B. cereus is not found in large numbers in fecal specimens. Therefore food sample is more useful.\")\n",
      "sample hard negative: ('Chronic urethral obstruction due to benign prismatic hyperplasia can lead to the following change in kidney parenchyma', \"Ans. a (MCU). (Ref. Sutton Radiology 7th ed. 1017, 1061)- MCU is IOC for PU valve and VUR.Posterior urethral valves (PUV)# Varying degree of chronic urethral obstruction due to fusion and prominence of plicae colliculi, normal concentric folds of urethra.# Usually located in posterior urethra just distal to the level verumontanum.c;# It is the most common cause of severe obstructive uropathy in infants and children.# MCU is 'gold standard' in diagnosis of PUV.# Rx: Cystoscopic fulguration of the valves.Three types of PUV are described :\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of generated pairs:\")\n",
    "print(f\"positives: {len(positives)} | easy_negatives: {len(easy_negatives)} | hard_negatives: {len(hard_negatives)}\")\n",
    "print(\"sample easy negative:\", easy_negatives[0] if easy_negatives else None)\n",
    "print(\"sample hard negative:\", hard_negatives[0] if hard_negatives else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3615aa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built negative index for 160869 unique queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating triplets: 100%|██████████| 160869/160869 [00:00<00:00, 331504.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 160869 triplet samples (query, positive, negative)\n"
     ]
    }
   ],
   "source": [
    "# (query, positive_passage, negative_passage)\n",
    "positives_clean = [(q, p) for (q, p) in positives if q and p]\n",
    "\n",
    "negatives = easy_negatives + hard_negatives\n",
    "negatives_clean = [(q, p) for (q, p) in negatives if q and p]\n",
    "\n",
    "# Build a dict mapping query -> list of negative passages\n",
    "from collections import defaultdict\n",
    "\n",
    "neg_by_query = defaultdict(list)\n",
    "for q, p in negatives_clean:\n",
    "    neg_by_query[q].append(p)\n",
    "\n",
    "print(f\"Built negative index for {len(neg_by_query)} unique queries\")\n",
    "\n",
    "# samples: (query, positive_passage, negative_passage)\n",
    "triplet_samples = []\n",
    "for q, pos_p in tqdm(positives_clean, desc=\"Creating triplets\"):\n",
    "    # Fast lookup: get negatives for this query\n",
    "    neg_for_q = neg_by_query.get(q, [])\n",
    "    \n",
    "    # Filter out the positive passage\n",
    "    neg_for_q = [p for p in neg_for_q if p != pos_p]\n",
    "    \n",
    "    if neg_for_q:\n",
    "        neg_p = random.choice(neg_for_q)\n",
    "        triplet_samples.append((q, pos_p, neg_p))\n",
    "\n",
    "random.shuffle(triplet_samples)\n",
    "print(f\"Created {len(triplet_samples)} triplet samples (query, positive, negative)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c55240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset - train: 144782, val: 16087\n",
      "Subset (10%) - train: 14478, val: 1608\n",
      "Use train_data_subset for fast prototyping, train_data for full training\n"
     ]
    }
   ],
   "source": [
    "# 90-10 train-val split\n",
    "split = int(0.9 * len(triplet_samples))\n",
    "train_data, val_data = triplet_samples[:split], triplet_samples[split:]\n",
    "\n",
    "# Use subset for faster iteration (10% of data) during prototyping\n",
    "subset_size = len(train_data) // 10\n",
    "train_data_subset = train_data[:subset_size]\n",
    "val_data_subset = val_data[:len(val_data)//10]\n",
    "\n",
    "print(f\"Full dataset - train: {len(train_data)}, val: {len(val_data)}\")\n",
    "print(f\"Subset (10%) - train: {len(train_data_subset)}, val: {len(val_data_subset)}\")\n",
    "print(\"Use train_data_subset for fast prototyping, train_data for full training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73cff91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def collate_batch_triplet(batch, max_len=128):\n",
    "    qs, pos_ps, neg_ps = zip(*batch)\n",
    "    \n",
    "    # Encode queries\n",
    "    enc_q = tokenizer(\n",
    "        list(qs),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Encode positive passages\n",
    "    enc_pos = tokenizer(\n",
    "        list(pos_ps),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Encode negative passages\n",
    "    enc_neg = tokenizer(\n",
    "        list(neg_ps),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return enc_q, enc_pos, enc_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9279c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingScorer(nn.Module):\n",
    "    def __init__(self, encoder, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_dim = encoder.config.hidden_size\n",
    "        \n",
    "        # Project to embedding space for ranking\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, enc_ips):\n",
    "        out = self.encoder(**enc_ips).last_hidden_state\n",
    "        \n",
    "        # Mean pooling over tokens\n",
    "        mask = enc_ips[\"attention_mask\"].unsqueeze(-1)  # [B, L, 1]\n",
    "        pooled = (out * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-9)  # [B, H]\n",
    "        \n",
    "        # Project to embedding space\n",
    "        embedding = self.projection(pooled)  # [B, embedding_dim]\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80522ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = RankingScorer(encoder, embedding_dim=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb0aac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# Ranking loss: Triplet Loss with margin\n",
    "def ranking_loss(emb_pos, emb_neg, margin=0.5):\n",
    "    \"\"\"Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
    "    Push negative embeddings away from positive embeddings.\n",
    "    \"\"\"\n",
    "    # Cosine similarity\n",
    "    pos_sim = F.cosine_similarity(emb_pos, emb_pos)  # [B], should be ~1.0\n",
    "    neg_sim = F.cosine_similarity(emb_pos, emb_neg)  # [B], should be < pos_sim\n",
    "    \n",
    "    # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
    "    # Want pos_sim > neg_sim by at least margin\n",
    "    loss = torch.clamp(margin - (pos_sim - neg_sim), min=0).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "352eb430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches per epoch: 453\n"
     ]
    }
   ],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(train_data_subset, batch_size=32, shuffle=True, collate_fn=collate_batch_triplet)\n",
    "val_loader = DataLoader(val_data_subset, batch_size=32, shuffle=False, collate_fn=collate_batch_triplet)\n",
    "\n",
    "print(f\"Training batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87e3d1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/453 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 453/453 [03:16<00:00,  2.31it/s, loss=0.1093]\n",
      "Validation: 100%|██████████| 51/51 [00:09<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: val_ranking_acc=0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 453/453 [03:35<00:00,  2.10it/s, loss=0.0971]\n",
      "Validation: 100%|██████████| 51/51 [00:09<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: val_ranking_acc=0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 453/453 [03:11<00:00,  2.37it/s, loss=0.0335]\n",
      "Validation: 100%|██████████| 51/51 [00:06<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: val_ranking_acc=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 453/453 [03:11<00:00,  2.37it/s, loss=0.0447]\n",
      "Validation: 100%|██████████| 51/51 [00:06<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: val_ranking_acc=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 453/453 [03:23<00:00,  2.22it/s, loss=0.0230]\n",
      "Validation: 100%|██████████| 51/51 [00:09<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: val_ranking_acc=0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "n = 5 # epochs\n",
    "for epoch in range(n):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for enc_q, enc_pos, enc_neg in pbar:\n",
    "        enc_q = {k: v.to(device) for k, v in enc_q.items()}\n",
    "        enc_pos = {k: v.to(device) for k, v in enc_pos.items()}\n",
    "        enc_neg = {k: v.to(device) for k, v in enc_neg.items()}\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            emb_q = model(enc_q)       # Query embeddings\n",
    "            emb_pos = model(enc_pos)   # Positive passage embeddings\n",
    "            emb_neg = model(enc_neg)   # Negative passage embeddings\n",
    "            \n",
    "            # Cosine similarity: query vs positive, query vs negative\n",
    "            pos_sim = F.cosine_similarity(emb_q, emb_pos)  # [B]\n",
    "            neg_sim = F.cosine_similarity(emb_q, emb_neg)  # [B]\n",
    "            \n",
    "            # Triplet loss: max(0, margin - (pos_sim - neg_sim))\n",
    "            loss = torch.clamp(0.5 - (pos_sim - neg_sim), min=0).mean()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        \n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    # Validation: check if positive is ranked higher than negative\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for enc_q, enc_pos, enc_neg in tqdm(val_loader, desc=\"Validation\"):\n",
    "            enc_q = {k: v.to(device) for k, v in enc_q.items()}\n",
    "            enc_pos = {k: v.to(device) for k, v in enc_pos.items()}\n",
    "            enc_neg = {k: v.to(device) for k, v in enc_neg.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                emb_q = model(enc_q)\n",
    "                emb_pos = model(enc_pos)\n",
    "                emb_neg = model(enc_neg)\n",
    "            \n",
    "            # Check: query similarity to positive > query similarity to negative\n",
    "            pos_sim = F.cosine_similarity(emb_q, emb_pos)\n",
    "            neg_sim = F.cosine_similarity(emb_q, emb_neg)\n",
    "            correct += (pos_sim > neg_sim).sum().item()\n",
    "            total += emb_q.shape[0]\n",
    "    \n",
    "    print(f\"epoch {epoch}: val_ranking_acc={correct/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b730f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ranking_scorer.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1a19bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Query:\n",
      "A policemen foo..a a person ln ing unconscious in iglu lateral position on the road with superficial injury to the face, bruises on the right arm, and injury to the lateral aspect of right knee. Nerve most probably injured:\n",
      "\n",
      "======================================================================\n",
      "Ranked passages (ascending energy = best match):\n",
      "======================================================================\n",
      "\n",
      "1. ✗ LOW ✓ GOLD\n",
      "   Similarity: 0.4146 | Energy: 0.5854\n",
      "   Ans. c. Common peroneal nerve Common peroneal nerve (L4, L5, Sl, S2) is the smaller terminal branch of sciatic nerve. The larger terminal branch of sciatic nerve is the tibial nerve. The common peroneal nerve is relative...\n",
      "\n",
      "2. ✗ LOW\n",
      "   Similarity: 0.3954 | Energy: 0.6046\n",
      "   curare notch ref : willey 10th ed\n",
      "\n",
      "3. ✗ LOW\n",
      "   Similarity: -0.0587 | Energy: 1.0587\n",
      "   The area posterior to the sternum is occupied by the right ventricle and hence is most likely to be injured in this case. The convex anterosuperior surface of the right ventricle makes up a large pa of the sternocoastal ...\n",
      "\n",
      "======================================================================\n",
      "Energy Score Guide:\n",
      "  Energy ≈ 0.0-0.3  → ✓ HIGH confidence (good match)\n",
      "  Energy ≈ 0.3-0.5  → ⚠ MEDIUM confidence (acceptable)\n",
      "  Energy ≈ 0.5+     → ✗ LOW confidence (poor match)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Ranking inference: compute energy scores\n",
    "def rank_passages_with_energy(model, tokenizer, query, passages, device=\"cuda\", max_len=128, batch_size=32):\n",
    "    \"\"\"Rank passages and compute energy scores.\n",
    "    \n",
    "    Energy = 1 - similarity (lower energy = better match, closer to 0)\n",
    "    Higher similarity = passage more relevant to query.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    similarity_scores = []\n",
    "    \n",
    "    autocast_device = \"cuda\" if str(device).startswith(\"cuda\") and torch.cuda.is_available() else \"cpu\"\n",
    "    with torch.no_grad(), torch.amp.autocast(autocast_device):\n",
    "        # Encode query separately\n",
    "        enc_query = tokenizer(\n",
    "            query,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        enc_query = {k: v.to(device) for k, v in enc_query.items()}\n",
    "        query_embedding = model(enc_query)  # [1, embedding_dim]\n",
    "        \n",
    "        # Score each passage\n",
    "        for i in range(0, len(passages), batch_size):\n",
    "            batch = passages[i : i + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch,  # Encode passages only\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            passage_embeddings = model(enc)  # [batch_size, embedding_dim]\n",
    "            \n",
    "            # Cosine similarity between query and each passage\n",
    "            sims = F.cosine_similarity(query_embedding, passage_embeddings)  # [batch_size]\n",
    "            similarity_scores.extend(sims.detach().cpu().tolist())\n",
    "    \n",
    "    # Convert similarity to energy: energy = 1 - similarity\n",
    "    # Lower energy (closer to 0) = better match\n",
    "    energy_scores = [1 - sim for sim in similarity_scores]\n",
    "    \n",
    "    # Sort by energy (ascending = best first, lowest energy = highest confidence)\n",
    "    ranked = sorted(zip(passages, similarity_scores, energy_scores), key=lambda x: x[2])\n",
    "    return ranked\n",
    "\n",
    "\n",
    "# Test on a random positive example\n",
    "source_pos = positives_clean if 'positives_clean' in globals() else [(q, p) for (q, p) in positives if q and p]\n",
    "q, gold = random.choice(source_pos)\n",
    "\n",
    "# Find easy/hard negatives for the same question\n",
    "easy_p = None\n",
    "hard_p = None\n",
    "\n",
    "if 'easy_negatives' in globals() and easy_negatives:\n",
    "    same_q_easy = [p for (qq, p) in easy_negatives if qq == q and p]\n",
    "    if same_q_easy:\n",
    "        easy_p = random.choice(same_q_easy)\n",
    "    else:\n",
    "        pool = [p for (_, p) in easy_negatives if p and p != gold]\n",
    "        easy_p = random.choice(pool) if pool else None\n",
    "\n",
    "if 'hard_negatives' in globals() and hard_negatives:\n",
    "    same_q_hard = [p for (qq, p) in hard_negatives if qq == q and p]\n",
    "    if same_q_hard:\n",
    "        hard_p = random.choice(same_q_hard)\n",
    "    else:\n",
    "        pool = [p for (_, p) in hard_negatives if p and p != gold]\n",
    "        hard_p = random.choice(pool) if pool else None\n",
    "\n",
    "# Build passages to rank\n",
    "test_passages = [gold]\n",
    "if easy_p: test_passages.append(easy_p)\n",
    "if hard_p: test_passages.append(hard_p)\n",
    "\n",
    "# Rank them with energy scores\n",
    "ranked = rank_passages_with_energy(model, tokenizer, q, test_passages, device=device, max_len=128, batch_size=32)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Query:\")\n",
    "print(q[:300])\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Ranked passages (ascending energy = best match):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, (passage, similarity, energy) in enumerate(ranked, 1):\n",
    "    snippet = (passage or \"\").replace(\"\\n\", \" \")[:220]\n",
    "    is_gold = \" ✓ GOLD\" if passage == gold else \"\"\n",
    "    \n",
    "    # Color-code energy: green if low (good), red if high (bad)\n",
    "    confidence = \"✓ HIGH\" if energy < 0.3 else \"⚠ MEDIUM\" if energy < 0.5 else \"✗ LOW\"\n",
    "    \n",
    "    print(f\"\\n{i}. {confidence}{is_gold}\")\n",
    "    print(f\"   Similarity: {similarity:.4f} | Energy: {energy:.4f}\")\n",
    "    print(f\"   {snippet}{'...' if passage and len(passage) > 220 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Energy Score Guide:\")\n",
    "print(\"  Energy ≈ 0.0-0.3  → ✓ HIGH confidence (good match)\")\n",
    "print(\"  Energy ≈ 0.3-0.5  → ⚠ MEDIUM confidence (acceptable)\")\n",
    "print(\"  Energy ≈ 0.5+     → ✗ LOW confidence (poor match)\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
